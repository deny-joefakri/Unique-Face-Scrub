{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/deny-joefakri/Unique-Face-Scrub/blob/main/ResNet50_Unique_Faces.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yBiSAwmnbBxW"
      },
      "source": [
        "# Import Lib\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T2cKSD9fbPZF"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras.layers import Input, Lambda, Dense, Flatten, Dropout\n",
        "from tensorflow.keras.models import Model, Sequential\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "POjsYfK8dMLS"
      },
      "outputs": [],
      "source": [
        "tf.random.set_seed(1234)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q4khMkW1dNH5"
      },
      "outputs": [],
      "source": [
        "image_generator = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=20,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest'\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SpsXGmRQdUob"
      },
      "outputs": [],
      "source": [
        "IMG_HEIGHT = 224\n",
        "IMG_WIDTH = 224"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VpNfnd5LhuKw",
        "outputId": "db956e4a-f376-4fe2-b9df-bccd7e7a6b0a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive  \n",
        "drive.mount('/content/drive')  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dBC15h_UiJgw"
      },
      "outputs": [],
      "source": [
        "train_dir = '/content/drive/MyDrive/Colab Notebooks/Dataset/face/face_dataset/train/'\n",
        "\n",
        "val_dir = '/content/drive/MyDrive/Colab Notebooks/Dataset/face/face_dataset/val/'\n",
        "\n",
        "test_dir = '/content/drive/MyDrive/Colab Notebooks/Dataset/face/face_dataset/test/'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5KJk6MYKhhmR",
        "outputId": "6389a3b7-1e5b-42e8-fdbb-233232cbcfc3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 3523 images belonging to 50 classes.\n",
            "Found 250 images belonging to 50 classes.\n",
            "Found 250 images belonging to 50 classes.\n"
          ]
        }
      ],
      "source": [
        "batch_size = 32\n",
        "input_shape = (224, 224, 3)\n",
        "\n",
        "# Preprocess the images\n",
        "\n",
        "\n",
        "training_set = image_generator.flow_from_directory(batch_size=batch_size,\n",
        "                                                   directory=train_dir,\n",
        "                                                   shuffle=True,\n",
        "                                                   target_size=input_shape[:2],\n",
        "                                                   class_mode=\"categorical\")\n",
        "\n",
        "validation_set = image_generator.flow_from_directory(batch_size=batch_size,\n",
        "                                                   directory=val_dir,\n",
        "                                                   shuffle=False,\n",
        "                                                   target_size=input_shape[:2],\n",
        "                                                   class_mode=\"categorical\")\n",
        "\n",
        "testing_set = image_generator.flow_from_directory(batch_size=batch_size,\n",
        "                                                   directory=test_dir,\n",
        "                                                   shuffle=False,\n",
        "                                                   target_size=input_shape[:2],\n",
        "                                                   class_mode=\"categorical\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.layers import Conv2D, MaxPooling2D, GlobalMaxPooling2D, Flatten, Dense, Dropout, Input, BatchNormalization\n",
        "from keras.callbacks import ReduceLROnPlateau\n",
        "\n",
        "\n",
        "def build_model(resnet):\n",
        "    input_data = Input(input_shape)\n",
        "    x = resnet(input_data)\n",
        "    x = GlobalMaxPooling2D()(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Dropout(0.3)(x)\n",
        "    x = Dense(128,activation='relu')(x) \n",
        "    output = Dense(50, activation='softmax')(x)\n",
        "    \n",
        "    resnet_model = Model(inputs=input_data, outputs=output)\n",
        "    \n",
        "    resnet_model.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
        "    \n",
        "    return resnet_model\n",
        "\n",
        "\n",
        "\n",
        "resnet = ResNet50(weights='imagenet', \n",
        "                      include_top=False, \n",
        "                      input_shape = input_shape)\n",
        "resnet.trainable = False\n",
        "model = build_model(resnet)\n",
        "model.summary()\n",
        "\n",
        "callbacks = [ReduceLROnPlateau(monitor='loss', factor=0.5, patience=5, min_lr=0.00001)]\n",
        "history = model.fit(training_set, epochs=5, \n",
        "                         verbose = 1,\n",
        "                         batch_size=32,\n",
        "                         callbacks=callbacks,\n",
        "                         validation_data=validation_set)\n",
        "# history = model.fit(trainX, trainY,\n",
        "#                          epochs = 15,\n",
        "#                          verbose = 1,\n",
        "#                          batch_size=32,\n",
        "#                          validation_data = (valX, valY),\n",
        "#                          callbacks=callbacks)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "MX0YeUzxtPsF",
        "outputId": "26e2503e-3851-4159-8f6d-ad3c3b930358"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "94765736/94765736 [==============================] - 1s 0us/step\n",
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_2 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
            "                                                                 \n",
            " resnet50 (Functional)       (None, 7, 7, 2048)        23587712  \n",
            "                                                                 \n",
            " global_max_pooling2d (Globa  (None, 2048)             0         \n",
            " lMaxPooling2D)                                                  \n",
            "                                                                 \n",
            " batch_normalization (BatchN  (None, 2048)             8192      \n",
            " ormalization)                                                   \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 2048)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 128)               262272    \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 50)                6450      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 23,864,626\n",
            "Trainable params: 272,818\n",
            "Non-trainable params: 23,591,808\n",
            "_________________________________________________________________\n",
            "Epoch 1/5\n",
            "111/111 [==============================] - 1144s 10s/step - loss: 0.1727 - accuracy: 0.0383 - val_loss: 0.1147 - val_accuracy: 0.0280 - lr: 0.0010\n",
            "Epoch 2/5\n",
            "111/111 [==============================] - 703s 6s/step - loss: 0.0972 - accuracy: 0.0659 - val_loss: 0.1029 - val_accuracy: 0.0360 - lr: 0.0010\n",
            "Epoch 3/5\n",
            "111/111 [==============================] - 702s 6s/step - loss: 0.0938 - accuracy: 0.0897 - val_loss: 0.0970 - val_accuracy: 0.0680 - lr: 0.0010\n",
            "Epoch 4/5\n",
            "111/111 [==============================] - 744s 7s/step - loss: 0.0927 - accuracy: 0.1025 - val_loss: 0.0925 - val_accuracy: 0.0760 - lr: 0.0010\n",
            "Epoch 5/5\n",
            " 43/111 [==========>...................] - ETA: 6:43 - loss: 0.0901 - accuracy: 0.1185"
          ]
        },
        {
          "output_type": "error",
          "ename": "UnknownError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mUnknownError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-572e9b556603>\u001b[0m in \u001b[0;36m<cell line: 30>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0mcallbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mReduceLROnPlateau\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmonitor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfactor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpatience\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_lr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.00001\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m history = model.fit(training_set, epochs=5, \n\u001b[0m\u001b[1;32m     31\u001b[0m                          \u001b[0mverbose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m                          \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     50\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     53\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     54\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mUnknownError\u001b[0m: Graph execution error:\n\nFileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/Colab Notebooks/Dataset/face/face_dataset/train/Emile_Hirsch/Emile_Hirsch_36015_18847.jpeg'\nTraceback (most recent call last):\n\n  File \"/usr/local/lib/python3.9/dist-packages/tensorflow/python/ops/script_ops.py\", line 267, in __call__\n    ret = func(*args)\n\n  File \"/usr/local/lib/python3.9/dist-packages/tensorflow/python/autograph/impl/api.py\", line 642, in wrapper\n    return func(*args, **kwargs)\n\n  File \"/usr/local/lib/python3.9/dist-packages/tensorflow/python/data/ops/from_generator_op.py\", line 198, in generator_py_func\n    values = next(generator_state.get_iterator(iterator_id))\n\n  File \"/usr/local/lib/python3.9/dist-packages/keras/engine/data_adapter.py\", line 902, in wrapped_generator\n    for data in generator_fn():\n\n  File \"/usr/local/lib/python3.9/dist-packages/keras/engine/data_adapter.py\", line 1049, in generator_fn\n    yield x[i]\n\n  File \"/usr/local/lib/python3.9/dist-packages/keras/preprocessing/image.py\", line 116, in __getitem__\n    return self._get_batches_of_transformed_samples(index_array)\n\n  File \"/usr/local/lib/python3.9/dist-packages/keras/preprocessing/image.py\", line 370, in _get_batches_of_transformed_samples\n    img = image_utils.load_img(\n\n  File \"/usr/local/lib/python3.9/dist-packages/keras/utils/image_utils.py\", line 422, in load_img\n    with open(path, \"rb\") as f:\n\nFileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/Colab Notebooks/Dataset/face/face_dataset/train/Emile_Hirsch/Emile_Hirsch_36015_18847.jpeg'\n\n\n\t [[{{node PyFunc}}]]\n\t [[IteratorGetNext]] [Op:__inference_train_function_10734]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def GetXY(gen):\n",
        "    listX = []\n",
        "    listY = []\n",
        "    for i in range(gen.__len__()):\n",
        "        gennext = gen.next()\n",
        "        listX.append(gennext[0])\n",
        "        listY.append(gennext[1])\n",
        "    x=np.concatenate(listX)\n",
        "    y=np.concatenate(listY)\n",
        "    return (x,y)\n",
        "    \n",
        "trainX,trainY = GetXY(training_set)\n",
        "valX,valY = GetXY(validation_set)\n",
        "testX,testY = GetXY(testing_set)"
      ],
      "metadata": {
        "id": "xRnQXgZY2opz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lgRL7O1ZzZvT"
      },
      "outputs": [],
      "source": [
        "training_set.samples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "My7LxTuyHSO4"
      },
      "outputs": [],
      "source": [
        "pd.DataFrame(history.history).plot(figsize=(10, 5))\n",
        "plt.grid(True)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EcpPawA4Jld_"
      },
      "outputs": [],
      "source": [
        "model.evaluate(testing_set)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CAW8AgvtJoe9"
      },
      "outputs": [],
      "source": [
        "test_pred = np.argmax(model.predict(testing_set), axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss, test_acc = model.evaluate(testing_set, steps=len(testing_set), verbose=1)\n",
        "print('Loss: %.3f' % (test_loss * 100.0))\n",
        "print('Accuracy: %.3f' % (test_acc * 100.0))"
      ],
      "metadata": {
        "id": "rzqIyOUv4p6n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ui-_d64mJrKK"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
        "\n",
        "\n",
        "y_val = testing_set.classes\n",
        "y_pred = np.argmax(model.predict(testing_set),axis=1)\n",
        "print(classification_report(y_val,y_pred))\n",
        "\n",
        "cm = confusion_matrix(y_val, y_pred)\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
        "disp.plot()\n",
        "plt.show()\n",
        "\n",
        "# print(classification_report(testing_set,test_pred))\n",
        "# print(confusion_matrix(testY, predict))\n",
        "\n",
        "\n",
        "\n",
        "# print(classification_report(testing_set,test_pred))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN6764e3KvP3MOFxPC7d9kU",
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}