{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/deny-joefakri/Unique-Face-Scrub/blob/main/VGGNet16_Unique_Faces.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yBiSAwmnbBxW"
      },
      "source": [
        "# Import Lib\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T2cKSD9fbPZF"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.applications.vgg16 import VGG16\n",
        "from tensorflow.keras.layers import Input, Lambda, Dense, Flatten, Dropout\n",
        "from tensorflow.keras.models import Model, Sequential\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "POjsYfK8dMLS"
      },
      "outputs": [],
      "source": [
        "tf.random.set_seed(1234)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q4khMkW1dNH5"
      },
      "outputs": [],
      "source": [
        "image_generator = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=20,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest'\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SpsXGmRQdUob"
      },
      "outputs": [],
      "source": [
        "IMG_HEIGHT = 224\n",
        "IMG_WIDTH = 224"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VpNfnd5LhuKw",
        "outputId": "89148fd1-6a3a-4e89-d8a9-1db66ef492d1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive  \n",
        "drive.mount('/content/drive')  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dBC15h_UiJgw"
      },
      "outputs": [],
      "source": [
        "train_dir = '/content/drive/MyDrive/Colab Notebooks/Dataset/face/face_dataset/train/'\n",
        "\n",
        "val_dir = '/content/drive/MyDrive/Colab Notebooks/Dataset/face/face_dataset/val/'\n",
        "\n",
        "test_dir = '/content/drive/MyDrive/Colab Notebooks/Dataset/face/face_dataset/test/'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5KJk6MYKhhmR",
        "outputId": "fd6afcc5-60bd-4c98-d084-5203602577e4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 3523 images belonging to 50 classes.\n",
            "Found 250 images belonging to 50 classes.\n",
            "Found 250 images belonging to 50 classes.\n"
          ]
        }
      ],
      "source": [
        "batch_size = 32\n",
        "input_shape = (224, 224, 3)\n",
        "\n",
        "# Preprocess the images\n",
        "\n",
        "\n",
        "# training_set = image_generator.flow_from_directory(batch_size=batch_size,\n",
        "#                                                    directory=train_dir,\n",
        "#                                                    shuffle=True,\n",
        "#                                                    target_size=input_shape[:2],\n",
        "#                                                    class_mode=\"categorical\")\n",
        "\n",
        "# validation_set = image_generator.flow_from_directory(batch_size=batch_size,\n",
        "#                                                    directory=val_dir,\n",
        "#                                                    shuffle=True,\n",
        "#                                                    target_size=input_shape[:2],\n",
        "#                                                    class_mode=\"categorical\")\n",
        "\n",
        "# testing_set = image_generator.flow_from_directory(batch_size=batch_size,\n",
        "#                                                    directory=test_dir,\n",
        "#                                                    shuffle=False,\n",
        "#                                                    target_size=input_shape[:2],\n",
        "#                                                    class_mode=\"categorical\")\n",
        "\n",
        "IMG_SIZE = (224, 224)\n",
        "train_datagen = ImageDataGenerator(rescale=1./255,\n",
        "                                   rotation_range=10,\n",
        "                                   width_shift_range=0.2, \n",
        "                                   height_shift_range=0.2,\n",
        "                                   zoom_range=0.25, \n",
        "                                   horizontal_flip=True, \n",
        "                                   samplewise_center=True, \n",
        "                                   samplewise_std_normalization=True,\n",
        "                                   fill_mode='nearest')\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "training_set = train_datagen.flow_from_directory(train_dir, target_size=input_shape[:2], \n",
        "                                         color_mode=\"rgb\",\n",
        "                                         batch_size=200, \n",
        "                                         shuffle=True,\n",
        "                                         class_mode=\"categorical\")\n",
        "\n",
        "testing_set = test_datagen.flow_from_directory(test_dir, target_size=input_shape[:2], \n",
        "                                         color_mode=\"rgb\",\n",
        "                                         batch_size=64, \n",
        "                                         shuffle=True,\n",
        "                                         class_mode=\"categorical\")\n",
        "\n",
        "validation_set = train_datagen.flow_from_directory(val_dir, target_size=input_shape[:2], \n",
        "                                         color_mode=\"rgb\",\n",
        "                                         batch_size=64, \n",
        "                                         shuffle=True,\n",
        "                                         class_mode=\"categorical\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def create_model(input_shape, n_classes, optimizer='rmsprop', fine_tune=0):\n",
        "    \"\"\"\n",
        "    Compiles a model integrated with VGG16 pretrained layers\n",
        "    \n",
        "    input_shape: tuple - the shape of input images (width, height, channels)\n",
        "    n_classes: int - number of classes for the output layer\n",
        "    optimizer: string - instantiated optimizer to use for training. Defaults to 'RMSProp'\n",
        "    fine_tune: int - The number of pre-trained layers to unfreeze.\n",
        "                If set to 0, all pretrained layers will freeze during training\n",
        "    \"\"\"\n",
        "    \n",
        "    # Pretrained convolutional layers are loaded using the Imagenet weights.\n",
        "    # Include_top is set to False, in order to exclude the model's fully-connected layers.\n",
        "    conv_base = VGG16(include_top=False,\n",
        "                     weights='imagenet', \n",
        "                     input_shape=input_shape)\n",
        "    \n",
        "    # Defines how many layers to freeze during training.\n",
        "    # Layers in the convolutional base are switched from trainable to non-trainable\n",
        "    # depending on the size of the fine-tuning parameter.\n",
        "    if fine_tune > 0:\n",
        "        for layer in conv_base.layers[:-fine_tune]:\n",
        "            layer.trainable = False\n",
        "    else:\n",
        "        for layer in conv_base.layers:\n",
        "            layer.trainable = False\n",
        "\n",
        "    # Create a new 'top' of the model (i.e. fully-connected layers).\n",
        "    # This is 'bootstrapping' a new top_model onto the pretrained layers.\n",
        "    top_model = conv_base.output\n",
        "    top_model = Flatten(name=\"flatten\")(top_model)\n",
        "    top_model = Dense(4096, activation='relu')(top_model)\n",
        "    top_model = Dense(1072, activation='relu')(top_model)\n",
        "    top_model = Dropout(0.2)(top_model)\n",
        "    output_layer = Dense(n_classes, activation='softmax')(top_model)\n",
        "    \n",
        "    # Group the convolutional base and new fully-connected layers into a Model object.\n",
        "    model = Model(inputs=conv_base.input, outputs=output_layer)\n",
        "\n",
        "    # Compiles the model for training.\n",
        "    model.compile(optimizer=optimizer, \n",
        "                  loss='binary_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "    \n",
        "    return model"
      ],
      "metadata": {
        "id": "L_rREiv5EF_j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.layers import Conv2D, MaxPooling2D, GlobalMaxPooling2D, Flatten, Dense, Dropout, Input, BatchNormalization\n",
        "from keras.callbacks import ReduceLROnPlateau\n",
        "from tensorflow.keras.optimizers.legacy import Adam\n",
        "from keras.optimizers import SGD\n",
        "\n",
        "BATCH_SIZE = 32\n",
        "input_shape = (224, 224, 3)\n",
        "optim_1 = Adam(learning_rate=0.001)\n",
        "n_classes=50\n",
        "\n",
        "n_steps = training_set.samples // BATCH_SIZE\n",
        "n_val_steps = validation_set.samples // BATCH_SIZE\n",
        "n_epochs = 10\n",
        "\n",
        "# First we'll train the model without Fine-tuning\n",
        "model = create_model(input_shape, n_classes, optim_1, fine_tune=0)\n",
        "\n",
        "\n",
        "\n",
        "# ModelCheckpoint callback - save best weights\n",
        "tl_checkpoint_1 = ModelCheckpoint(filepath='tl_model_v1.weights.best.hdf5',\n",
        "                                  save_best_only=True,\n",
        "                                  verbose=1)\n",
        "\n",
        "# EarlyStopping\n",
        "early_stop = EarlyStopping(monitor='val_loss',\n",
        "                           patience=10,\n",
        "                           restore_best_weights=True,\n",
        "                           mode='min')\n",
        "\n",
        "history = model.fit(training_set,\n",
        "                            batch_size=BATCH_SIZE,\n",
        "                            epochs=n_epochs,\n",
        "                            validation_data=validation_set,\n",
        "                            steps_per_epoch=n_steps,\n",
        "                            validation_steps=n_val_steps,\n",
        "                            verbose=1)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "MX0YeUzxtPsF",
        "outputId": "c6315c32-92b6-4575-a3d6-8f32a933846f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "InvalidArgumentError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-47b919ca4f84>\u001b[0m in \u001b[0;36m<cell line: 31>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     29\u001b[0m                            mode='min')\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m history = model.fit(training_set,\n\u001b[0m\u001b[1;32m     32\u001b[0m                             \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m                             \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_epochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     50\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     53\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     54\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mInvalidArgumentError\u001b[0m: Graph execution error:\n\nDetected at node 'gradient_tape/binary_crossentropy/logistic_loss/mul/BroadcastGradientArgs' defined at (most recent call last):\n    File \"/usr/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"/usr/lib/python3.9/runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"/usr/local/lib/python3.9/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n      app.launch_new_instance()\n    File \"/usr/local/lib/python3.9/dist-packages/traitlets/config/application.py\", line 992, in launch_instance\n      app.start()\n    File \"/usr/local/lib/python3.9/dist-packages/ipykernel/kernelapp.py\", line 619, in start\n      self.io_loop.start()\n    File \"/usr/local/lib/python3.9/dist-packages/tornado/platform/asyncio.py\", line 215, in start\n      self.asyncio_loop.run_forever()\n    File \"/usr/lib/python3.9/asyncio/base_events.py\", line 601, in run_forever\n      self._run_once()\n    File \"/usr/lib/python3.9/asyncio/base_events.py\", line 1905, in _run_once\n      handle._run()\n    File \"/usr/lib/python3.9/asyncio/events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/usr/local/lib/python3.9/dist-packages/tornado/ioloop.py\", line 687, in <lambda>\n      lambda f: self._run_callback(functools.partial(callback, future))\n    File \"/usr/local/lib/python3.9/dist-packages/tornado/ioloop.py\", line 740, in _run_callback\n      ret = callback()\n    File \"/usr/local/lib/python3.9/dist-packages/tornado/gen.py\", line 821, in inner\n      self.ctx_run(self.run)\n    File \"/usr/local/lib/python3.9/dist-packages/tornado/gen.py\", line 782, in run\n      yielded = self.gen.send(value)\n    File \"/usr/local/lib/python3.9/dist-packages/ipykernel/kernelbase.py\", line 361, in process_one\n      yield gen.maybe_future(dispatch(*args))\n    File \"/usr/local/lib/python3.9/dist-packages/tornado/gen.py\", line 234, in wrapper\n      yielded = ctx_run(next, result)\n    File \"/usr/local/lib/python3.9/dist-packages/ipykernel/kernelbase.py\", line 261, in dispatch_shell\n      yield gen.maybe_future(handler(stream, idents, msg))\n    File \"/usr/local/lib/python3.9/dist-packages/tornado/gen.py\", line 234, in wrapper\n      yielded = ctx_run(next, result)\n    File \"/usr/local/lib/python3.9/dist-packages/ipykernel/kernelbase.py\", line 539, in execute_request\n      self.do_execute(\n    File \"/usr/local/lib/python3.9/dist-packages/tornado/gen.py\", line 234, in wrapper\n      yielded = ctx_run(next, result)\n    File \"/usr/local/lib/python3.9/dist-packages/ipykernel/ipkernel.py\", line 302, in do_execute\n      res = shell.run_cell(code, store_history=store_history, silent=silent)\n    File \"/usr/local/lib/python3.9/dist-packages/ipykernel/zmqshell.py\", line 539, in run_cell\n      return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n    File \"/usr/local/lib/python3.9/dist-packages/IPython/core/interactiveshell.py\", line 2975, in run_cell\n      result = self._run_cell(\n    File \"/usr/local/lib/python3.9/dist-packages/IPython/core/interactiveshell.py\", line 3030, in _run_cell\n      return runner(coro)\n    File \"/usr/local/lib/python3.9/dist-packages/IPython/core/async_helpers.py\", line 78, in _pseudo_sync_runner\n      coro.send(None)\n    File \"/usr/local/lib/python3.9/dist-packages/IPython/core/interactiveshell.py\", line 3257, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"/usr/local/lib/python3.9/dist-packages/IPython/core/interactiveshell.py\", line 3473, in run_ast_nodes\n      if (await self.run_code(code, result,  async_=asy)):\n    File \"/usr/local/lib/python3.9/dist-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"<ipython-input-10-47b919ca4f84>\", line 31, in <cell line: 31>\n      history = model.fit(training_set,\n    File \"/usr/local/lib/python3.9/dist-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.9/dist-packages/keras/engine/training.py\", line 1685, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"/usr/local/lib/python3.9/dist-packages/keras/engine/training.py\", line 1284, in train_function\n      return step_function(self, iterator)\n    File \"/usr/local/lib/python3.9/dist-packages/keras/engine/training.py\", line 1268, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/usr/local/lib/python3.9/dist-packages/keras/engine/training.py\", line 1249, in run_step\n      outputs = model.train_step(data)\n    File \"/usr/local/lib/python3.9/dist-packages/keras/engine/training.py\", line 1054, in train_step\n      self.optimizer.minimize(loss, self.trainable_variables, tape=tape)\n    File \"/usr/local/lib/python3.9/dist-packages/keras/optimizers/optimizer.py\", line 542, in minimize\n      grads_and_vars = self.compute_gradients(loss, var_list, tape)\n    File \"/usr/local/lib/python3.9/dist-packages/keras/optimizers/optimizer.py\", line 275, in compute_gradients\n      grads = tape.gradient(loss, var_list)\nNode: 'gradient_tape/binary_crossentropy/logistic_loss/mul/BroadcastGradientArgs'\nIncompatible shapes: [200,10] vs. [200,50]\n\t [[{{node gradient_tape/binary_crossentropy/logistic_loss/mul/BroadcastGradientArgs}}]] [Op:__inference_train_function_1897]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lgRL7O1ZzZvT"
      },
      "outputs": [],
      "source": [
        "training_set.samples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "My7LxTuyHSO4"
      },
      "outputs": [],
      "source": [
        "pd.DataFrame(history.history).plot(figsize=(10, 5))\n",
        "plt.grid(True)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EcpPawA4Jld_"
      },
      "outputs": [],
      "source": [
        "model.evaluate(testing_set)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CAW8AgvtJoe9"
      },
      "outputs": [],
      "source": [
        "test_pred = np.argmax(model.predict(testing_set), axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss, test_acc = model.evaluate(testing_set, steps=len(testing_set), verbose=1)\n",
        "print('Loss: %.3f' % (test_loss * 100.0))\n",
        "print('Accuracy: %.3f' % (test_acc * 100.0))"
      ],
      "metadata": {
        "id": "rzqIyOUv4p6n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ui-_d64mJrKK"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
        "\n",
        "y_val = testing_set.classes\n",
        "y_pred = np.argmax(model.predict(testing_set),axis=1)\n",
        "print(classification_report(y_val,y_pred))\n",
        "\n",
        "cm = confusion_matrix(y_val, y_pred)\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
        "disp.plot()\n",
        "plt.show()\n",
        "\n",
        "# print(classification_report(testing_set,test_pred))\n",
        "# print(confusion_matrix(testY, predict))\n",
        "\n",
        "\n",
        "\n",
        "# print(classification_report(testing_set,test_pred))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNN1jmou9f7hNwvieasUm9+",
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}